{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcdb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Input directory not found at 'path/to/your/input_data'\n",
      "Please update the INPUT_DIRECTORY variable before running the script.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def filter_and_recount_sentences(input_tsv_path: str, output_tsv_path: str):\n",
    "    \"\"\"\n",
    "    Filters a TSV file based on the word count of its first column.\n",
    "\n",
    "    It removes rows where the word count in the first column is less than 6\n",
    "    or greater than 55 and saves the result to a new file.\n",
    "\n",
    "    Args:\n",
    "        input_tsv_path (str): The path to the input TSV file.\n",
    "        output_tsv_path (str): The path where the filtered TSV file will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the input TSV file.\n",
    "        df = pd.read_csv(input_tsv_path, sep='\\t')\n",
    "\n",
    "        # Check if the DataFrame has any columns.\n",
    "        if df.columns.empty:\n",
    "            print(f\"Warning: The file {input_tsv_path} is empty or has no columns. Skipping.\")\n",
    "            return\n",
    "\n",
    "        # --- MODIFIED: Automatically use the first column for filtering ---\n",
    "        column_to_filter = df.columns[0]\n",
    "        # --- End of modification ---\n",
    "\n",
    "        # Calculate the word count for the first column.\n",
    "        # This handles potential non-string or NaN values by converting to string,\n",
    "        # filling NaNs with an empty string, and then splitting.\n",
    "        df['calculated_word_count'] = df[column_to_filter].astype(str).fillna('').str.split().str.len()\n",
    "\n",
    "        # Filter the DataFrame based on the calculated word count.\n",
    "        initial_rows = len(df)\n",
    "        filtered_df = df[(df['calculated_word_count'] >= 6) & (df['calculated_word_count'] <= 55)]\n",
    "        final_rows = len(filtered_df)\n",
    "\n",
    "        # Save the filtered DataFrame to the output file, dropping the temporary column.\n",
    "        filtered_df.drop(columns=['calculated_word_count']).to_csv(output_tsv_path, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"Filtering complete based on the first column: '{column_to_filter}'. âœ…\")\n",
    "        print(f\"Initial number of sentences: {initial_rows}\")\n",
    "        print(f\"Number of sentences removed: {initial_rows - final_rows}\")\n",
    "        print(f\"Final number of sentences: {final_rows}\")\n",
    "        print(f\"Filtered data saved to: {output_tsv_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {input_tsv_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while processing {input_tsv_path}: {e}\")\n",
    "\n",
    "\n",
    "def process_directory(input_dir: str, output_dir: str):\n",
    "    \"\"\"\n",
    "    Recursively processes all tab-separated files in a directory structure.\n",
    "\n",
    "    For each file, it applies the filter_and_recount_sentences function and\n",
    "    recreates the same directory structure in the specified output directory.\n",
    "    The filtering is always based on the word count of the first column in each file.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The path to the parent input directory.\n",
    "        output_dir (str): The path to the parent output directory where the\n",
    "                          filtered structure will be saved.\n",
    "    \"\"\"\n",
    "    print(f\"Starting to process directory: {input_dir}\")\n",
    "    # os.walk traverses the directory tree top-down.\n",
    "    for dirpath, _, filenames in os.walk(input_dir):\n",
    "        # Create a corresponding directory structure in the output directory.\n",
    "        relative_path = os.path.relpath(dirpath, input_dir)\n",
    "        output_subdir = os.path.join(output_dir, relative_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "        for filename in filenames:\n",
    "            # Construct the full path for input and output files.\n",
    "            input_file = os.path.join(dirpath, filename)\n",
    "            output_file = os.path.join(output_subdir, filename)\n",
    "\n",
    "            print(f\"\\nProcessing file: {input_file}\")\n",
    "            # Apply the filtering function to the current file.\n",
    "            filter_and_recount_sentences(input_file, output_file)\n",
    "\n",
    "    print(\"\\nDirectory processing complete.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- USAGE INSTRUCTIONS ---\n",
    "    # 1. Replace \"path/to/your/input_data\" with the actual path to your directory.\n",
    "    # 2. Replace \"path/to/your/output_data\" with where you want to save the filtered results.\n",
    "    INPUT_DIRECTORY = \"Domain_Wise_Arranged_Parallel\"\n",
    "    OUTPUT_DIRECTORY = \"test_filtered2_copy\"\n",
    "\n",
    "    # --- Code for dummy data creation (Commented out) ---\n",
    "    # # Create the main input directory.\n",
    "    # os.makedirs(INPUT_DIRECTORY, exist_ok=True)\n",
    "    \n",
    "    # # Create a subdirectory inside the input directory.\n",
    "    # os.makedirs(os.path.join(INPUT_DIRECTORY, \"en-fr\"), exist_ok=True)\n",
    "\n",
    "    # # Create a sample TSV file in the main directory.\n",
    "    # data1 = {\n",
    "    #     'english_sentence': [\n",
    "    #         \"This is a short sentence.\",  # 5 words, should be removed\n",
    "    #         \"This is a perfectly acceptable sentence for our use case.\",  # 10 words\n",
    "    #         \"One two three four five six.\", # 6 words\n",
    "    #         \"This sentence is just right.\" # 5 words, should be removed\n",
    "    #     ],\n",
    "    #     'score': [0.9, 0.95, 0.88, 0.92]\n",
    "    # }\n",
    "    # df1 = pd.DataFrame(data1)\n",
    "    # df1.to_csv(os.path.join(INPUT_DIRECTORY, \"data_file_1.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "    # # Create another sample TSV file in the subdirectory.\n",
    "    # data2 = {\n",
    "    #     'french_version': [\n",
    "    #         \"Ceci est une phrase parfaite.\", # 5 words, should be removed\n",
    "    #         \"Un deux trois quatre cinq six sept huit neuf dix.\", # 10 words\n",
    "    #         \"Cette phrase contient exactement six mots pour le test.\", # 9 words\n",
    "    #         \"trop court\" # 2 words, should be removed\n",
    "    #     ],\n",
    "    #     'quality_metric': [0.85, 0.91, 0.89, 0.7]\n",
    "    # }\n",
    "    # df2 = pd.DataFrame(data2)\n",
    "    # df2.to_csv(os.path.join(INPUT_DIRECTORY, \"en-fr\", \"data_file_2.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "    # print(\"--- Created dummy files and directories for testing. ---\")\n",
    "    \n",
    "    # Run the processing function.\n",
    "    if os.path.isdir(INPUT_DIRECTORY):\n",
    "        process_directory(INPUT_DIRECTORY, OUTPUT_DIRECTORY)\n",
    "        print(\"\\n--- Script finished. ---\")\n",
    "        print(f\"Check the '{OUTPUT_DIRECTORY}' folder for the results.\")\n",
    "    else:\n",
    "        print(f\"Error: Input directory not found at '{INPUT_DIRECTORY}'\")\n",
    "        print(\"Please update the INPUT_DIRECTORY variable before running the script.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
